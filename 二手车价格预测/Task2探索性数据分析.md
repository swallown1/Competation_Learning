# Task2 探索性数据分析(EDA)

----
>day2:今天进行的是EDA部分，也就是数据探索性分析

### EDA的目标

>-主要在于熟悉数据集，了解数据集，对数据集进行验证，为下一步特征工程做基础。
>- 当了解了数据集之后我们下一步就是要去了解变量间的相互关系以及变量与预测值之间的存在关系。
>- 引导数据科学从业者进行数据处理以及特征工程的步骤,使数据集的结构和特征集让接下来的预测问题更加可靠。
>- 完成对于数据的探索性分析，并对于数据进行一些图表或者文字总结并打卡。


### 判断数据的缺失和异常
这部分是对给出的原始数据进行整理，处理缺失值的大体手段可以分为：删除、填充、映射到高维。
 - **删除**：也就是将存在遗漏信息属性值的对象（元组，记录）删除，从而得到一个完备的信息表。但是当缺失数据所占比例较大，特别当遗漏数据非随机分布时，这种方法可能导致数据发生偏离，从而引出错误的结论。
-  **填充**：用一定的值去填充空值，从而使信息表完备化。通常基于统计学原理，根据初始数据集中其余对象取值的分布情况来对一个缺失值进行填充。常用的方法有 人工填写、特殊值填充(**NaN作为一种特殊值**)、平均值填充(**数值型属性用均值，非数值型用频率最高值**)、热卡填充(就近补齐)、回归(属性是线性相关时比较好)、多重插补、c4.5等。还有就是不处理，在对树结构算法，贝叶斯网络以及深度学习方法都是可以的。[详情](https://zhuanlan.zhihu.com/p/33996846)
-  **映射到高维空间**，采用独热码编码（one-hot）技术。将包含K个离散取值范围的属性值扩展为K+1个属性值，若该属性值缺失，则扩展后的第K+1个属性值置为1。这种做法是最精确的做法，保留了所有的信息，也未添加任何额外信息，若预处理时把所有的变量都这样处理，会大大增加数据的维度。


##### 查看属性缺失值方法：
**1.计数法**
> - DF.isnull().sum() 统计各变量的缺失值情况。
> -  DF.info()  可以查看个属性的非空值总以及数值类型
 >-  DF.serise.unique()  查看Series对象的唯一值
 >-  DF.Series.value_counts():查看Series对象的唯一值和计数

**2.图表法**
    
 >1.msno.matrix() 可以快速直观地挑选出图案的数据完成
>2.msno.bar(Test_data.sample(1000))是列的无效的简单可视化
>3.msno.heatmap()相关性热图措施无效的相关性：一个变量的存在或不存在如何强烈影响的另一个的存在.

对于上面查找到的缺失值，如果确实数不多的情况，根据不同属性的类型及情况，采用不同的方法就行补充。**数值型属性用均值的方式补充，非数值型用该属性频率最高值补充**、**对于一些树模型(c4.5,xgboost等)也可以不处理**
虽然通过上面的方法可以看出缺失值的情况，但对于异常值的情况却不能明显的观察到。所以还要查看属性的异常值。

#### 查看与处理异常值方法
异常值指的不是空值，而是一些没有意义的值。比如 ‘-’、NaN等
1.查看
> - value_counts() 查看所有类型值及总数
> - unique() 查看所有不同值

2.处理
> - replace('-',np.nan,inplace=True)方法，将异常值进行替换
> - fillna()对异常值或者空值进行填充

这里指的异常值是数据中的一些非正常值，同时异常值又是和数据分布相关的，比如一些噪音特别大的数据，也可以称为是异常值，在处理这些值得时候基本遵循以下原则。

>

### 了解预测值的分布情况

对于预测值的分布情况观察，如果是回归，看看均值、方差，画画直方图；如果是分类，看看各类的比例，是否平衡。通过观察对y的分布进行处理，更好的减少噪音值对模型的泛化能力产生的影响。

**查看分布的操作**
>单元分布 sns.distplot(y,kde=False)
>  - 直方图（hist）+内核密度函数（kde）
>     hist 、 kde参数可以控制单变量的一个直方图和内核密度函数曲线，快速的了解单变量的一个分布情况。
> - 控制拟合的参数分布图形 ：fit参数用于画出不同分布的曲线图，便于观察数据符合哪一类的分布，其需要传入的是scipy 中的分布类型。johnsonsu(无界约翰逊分布)、正态分布、对数分布等。

> 偏度和峰度都是统计量 
> - 偏度Skewness(三阶) :指的是分布偏斜方向和程度的度量
>          偏度定义中包括正态分布（偏度=0），右偏分布（也叫正偏分布，其偏度>0），左偏分布（也叫负偏分布，其偏度<0）
> - 峰度Kurtosis (四阶):表征概率密度分布曲线在平均值处峰值高低的特征数
>峰度包括正态分布（峰度值=3），厚尾（峰度值>3），瘦尾（峰度值<3）  直观的理解就是指越小越尖，越大就越扁
> - [skew、kurt说明参考](https://www.cnblogs.com/wyy1480/p/10474046.html)

通过查看的方法，观察到预测值的情况以后，对于存在的一些异常值(例如长尾数据，)可以考虑将一些出现频次特别少的数据可以当作异常值去除掉。同时对于分布比较乱的情况，比较常用的trick进行log处理，使得分布的更加的均匀一些。

除了上面对单变量进行处理，还可以考虑做一些双变量核密度估计，以及对于离散值的分布情况也可以进行直观的观察。

> - kdeplot :可用于对单变量和双变量进行核密度估计并可视化.
> - rugplot:用于绘制出一维数组中数据点实际的分布位置情况，即不添加任何数学意义上的拟合，单纯的将记录值在坐标轴上表现出来.**这更适合观察到离散行数据的分布情况**
> - [详细参数](https://www.cnblogs.com/feffery/p/11128113.html)

 [此处是多变量之间的关系可视化，可视化更多学习可参考很不错的文章](https://www.jianshu.com/p/6e18d21a4cad)

通过这些方法的观察，可以更好的看出单变量或双变量的分布情况，更好的去除一些异常值，是其分布更符合特定的分布情况

>  问题：回归(离散)型预测值满足什么样的分布会比较好？以及常用什么处理方法达到特定的分布状态？


### 了解类别特征和数字特征
首先我们需要对所有的特征有一个大致的分析，分析其是类别特征还是数字特征，不同的特征会采用不同的方式进行处理，同时对于不同的模型对于特征类型也有要求。
> (比如在XGBoost和其他的Boosting Tree中，使用的Tree都是cart回归树，这也就意味着该类提升树算法只接受数值特征输入，不直接支持类别特征)
#### 1.数字特征分析：
对于数字型特征根据情况又是可能进行分桶的操作，可以减少数据的范围大小。同时还可以将数字型特征和预测值进行**相关性分析**。主要是为了观察不同特征与预测值的相关程度。(这里相关程度指的是数值之间的相互影响程度)

同时我们可以对特征的分布进行观察，查看特征得 偏度和峰值。目的是为了让特征可以有一个更好的分布情况，减少一些异常值的影响。

主要的操作
> -  相关性分析：sns.heatmap()函数，其中数值越大代表相关程度越大。[具体参数](https://zhuanlan.zhihu.com/p/96040773)
>  - 查看其skew和kurt以及可视化其分布：skew()、kurt()、distplot()

这里也可以对数字特征与预测值之间进行多变量关系的可视化。

> 问题：如何根据可视化图看出特征和预测值之间有线性关系？以及有了线性关系是否表示该特征对于模型学习更重要？


#### 2.类别特征分析：
类别特征也分为数字离散型和非数字离散型。对于非数字型类别特征的处理有两种，一种是转化成数字型，一种是转化成one-hot(映射到高维空间) [可参考](https://zhuanlan.zhihu.com/p/90782025)。对于数字型类别特征，可以通过不同的可视化方式来反应器分布状况，具体方法如下：

**a、箱形图可视化**
      箱形图显示一组数据分散情况资料的统计图。它能显示出一组数据的最大值、最小值、中位数及上下四分位数。
 sns.boxplot() 函数: [详情参考](https://blog.csdn.net/LuohenYJ/article/details/90677918)

**b、小提琴图可视化**
      它显示了定量数据在一个（或多个）分类变量的多个层次上的分布，这些分布可以进行比较。不像箱形图中所有绘图组件都对应于实际数据点，小提琴绘图以基础分布的核密度估计为特征。
sns.violinplot() 函数: [详情参考](https://zhuanlan.zhihu.com/p/34059825)

**c、柱形图可视化**
      利用矩阵条的高度反映数值变量的集中趋势，以及使用errorbar功能（差棒图）来估计变量之间的差值统计。请谨记bar plot展示的是某种变量分布的平均值，当需要精确观察每类变量的分布趋势，boxplot与violinplot往往是更好的选择。
sns.barplot() 函数: [详情参考](https://zhuanlan.zhihu.com/p/24553277)

**d、类别频数可视化**
      将它认为一种应用到分类变量的直方图，也可认为它是用以比较类别间计数差，调用count函数的barplot。
sns.countplot() 函数: [详情参考](https://zhuanlan.zhihu.com/p/24553277)


### 各种科学库
#### 1.pandas：
**数据读取**
  -  read_csv 功能：从文件、URL、文件新对象中加载带有分隔符的数据，默认分隔符是逗号
      -  sep : str, default ‘,’  指定分隔符。
      -  delimiter : str, default None  定界符，备选分隔符（如果指定该参数，则sep参数失效）
      -  [详细介绍](https://www.cnblogs.com/datablog/p/6127000.html)

 - read_tabel  功能：从文件、URL、文件型对象中加载带分隔符的数据，默认分隔符为制表符("\t")。  详细参数点击[这里](https://www.cnblogs.com/datablog/p/6127000.html)

 - pd.read_excel(filename)：从Excel文件导入数据
 - pd.read_sql(query, connection_object)：从SQL表/库导入数据
 - pd.read_json(json_string)：从JSON格式的字符串导入数据
 - pd.read_html(url)：解析URL、字符串或者HTML文件，抽取其中的tables表格
 - pd.read_clipboard()：从你的粘贴板获取内容，并传给read_table()
 - pd.DataFrame(dict)：从字典对象导入数据，Key是列名，Value是数据

---
**查看、检查数据**

*   df.head(n)：查看DataFrame对象的前n行
*   df.tail(n)：查看DataFrame对象的最后n行
*   df.shape()：查看行数和列数
*   df.info()：查看索引、数据类型和内存信息
*   df.describe()：每列的统计量，个数count、平均值mean、方差std、最小值min、中位数25% 50% 75% 、以及最大值
*   s.value_counts(dropna=False)：查看Series对象的唯一值和计数
*   df.apply(pd.Series.value_counts)：查看DataFrame对象中每一列的唯一值和计数

[盘点Pandas 的100个常用函数](https://zhuanlan.zhihu.com/p/86816441)

#### 1.可视化库：

**missingno：**
用来快速可视化缺失值。
> - msno.matrix(data, labels=True):无效矩阵的数据密集显示，白线越多，代表缺失值越多。
> - msno.bar(data):列的无效的简单可视化,利用条形图可以更直观的看出每个变量缺失的比例和数量情况。
> -  msno.heatmap(data):相关性热图措施无效的相关性,一个变量的存在或不存在如何强烈影响的另一个的存在。热度值是1，代表的是，当rater1缺失时，rater2也百分之百缺失，表示的是两个特征之间的关系。

**seaborn：**
要求原始数据的输入类型为 pandas 的 Dataframe 或 Numpy 数组.

> - subplots(ncols=列数, nrows=行数[, figsize=图片大小, ...]) :绘制子图一般使用 subplots 和 subplot 函数.
> - sns.barplot("X", "y", palette="RdBu_r", data=df) :直方图显示。
> - sns.distplot(df.sepal_length, bins=20, kde=True, rug=True):课同时显示直方图和密度分布图。
> - sns.pairplot()  点图，看所有数据的一个聚类情况。
